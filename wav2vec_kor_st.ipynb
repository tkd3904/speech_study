{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hgtk in /home/shin/anaconda3/envs/tensor/lib/python3.10/site-packages (0.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install hgtk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import hgtk\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            wav_path  \\\n",
      "0  /mnt/c/Users/tkd39/stt/1.Training/D03/J13/S000...   \n",
      "1  /mnt/c/Users/tkd39/stt/1.Training/D03/J13/S000...   \n",
      "2  /mnt/c/Users/tkd39/stt/1.Training/D03/J13/S000...   \n",
      "3  /mnt/c/Users/tkd39/stt/1.Training/D03/J13/S000...   \n",
      "4  /mnt/c/Users/tkd39/stt/1.Training/D03/J13/S000...   \n",
      "\n",
      "                                     decomposed_text  \n",
      "0  o/ n/ ㄴㅔ ㄱㅏㅁㅅㅏㅎㅏㅂㄴㅣㄷㅏ. (NCS)/(ㅇㅔㄴㅆㅣㅇㅔㅅㅡ) ㄱㅛㅇㅠㄱ...  \n",
      "1                                 o/ n/ ㄴㅔ ㅇㅕㅂㅗㅅㅔㅇㅛ.  \n",
      "2  o/ n/ ㅇㅏ ㄴㅔ ㅈㅓㄱㅣ ㄱㅡ (NCS)/(ㅇㅔㄴㅆㅣㅇㅔㅅㅡ) ㅇㅣㄴㅅㅏㄷㅏㅁ...  \n",
      "3  o/ n/ ㅇㅏ ㄴㅔ ㅁㅏㅈㅅㅡㅂㄴㅣㄷㅏ. ㅎㅗㅁㅍㅔㅇㅣㅈㅣㅇㅔ ㄴㅏㅇㅘㅇㅣㅆㄴㅡㄴ...  \n",
      "4                            o/ n/ ㄴㅔ ㅇㅏㄹㄱㅔㅆㅅㅡㅂㄴㅣㄷㅏ.  \n"
     ]
    }
   ],
   "source": [
    "# 기본 경로 설정 (폴더의 최상위 경로로 변경하세요)\n",
    "base_dir = '/mnt/c'\n",
    "\n",
    "# 데이터 저장을 위한 리스트 초기화\n",
    "data = []\n",
    "\n",
    "# os.walk를 사용하여 모든 하위 디렉토리 탐색\n",
    "for root, dirs, files in os.walk(base_dir):\n",
    "    # 각 파일에 대해 처리\n",
    "    for file in files:\n",
    "        # 파일 확장자에 따라 처리 분기\n",
    "        if file.endswith('.txt'):\n",
    "            txt_path = os.path.join(root, file)\n",
    "            wav_path = os.path.join(root, file.replace('.txt', '.wav'))\n",
    "\n",
    "            # 대응되는 .wav 파일이 있는지 확인\n",
    "            if os.path.exists(wav_path):\n",
    "                # 텍스트 파일 읽기\n",
    "                with open(txt_path, 'r', encoding='utf-8') as f:\n",
    "                    text = f.read().strip()\n",
    "\n",
    "                # 한글 자음과 모음으로 분리\n",
    "                decomposed_text = hgtk.text.decompose(text, compose_code='')\n",
    "\n",
    "                # 데이터 추가\n",
    "                data.append({\n",
    "                    'wav_path': wav_path,\n",
    "                    'decomposed_text': decomposed_text\n",
    "                })\n",
    "\n",
    "# 데이터프레임 생성\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 결과 확인\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('/mnt/c/datasets.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/mnt/c/datasets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_korean(text):\n",
    "    cleaned_text = re.sub(r'[^ㄱ-ㅎㅏ-ㅣ가-힣\\s]', '', text)\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text).strip()\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wav_path</th>\n",
       "      <th>decomposed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/mnt/c/Users/tkd39/stt/1.Training/D03/J13/S000...</td>\n",
       "      <td>ㄴㅔ ㄱㅏㅁㅅㅏㅎㅏㅂㄴㅣㄷㅏ ㅇㅔㄴㅆㅣㅇㅔㅅㅡ ㄱㅛㅇㅠㄱㄱㅘㅈㅓㅇ ㅁㅜㄴㅇㅢ ㅊㅔㅎ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/mnt/c/Users/tkd39/stt/1.Training/D03/J13/S000...</td>\n",
       "      <td>ㄴㅔ ㅇㅕㅂㅗㅅㅔㅇㅛ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/mnt/c/Users/tkd39/stt/1.Training/D03/J13/S000...</td>\n",
       "      <td>ㅇㅏ ㄴㅔ ㅈㅓㄱㅣ ㄱㅡ ㅇㅔㄴㅆㅣㅇㅔㅅㅡ ㅇㅣㄴㅅㅏㄷㅏㅁㄷㅏㅇㅈㅏ ㄱㅣㅂㅗㄴ ㅅㅣ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/mnt/c/Users/tkd39/stt/1.Training/D03/J13/S000...</td>\n",
       "      <td>ㅇㅏ ㄴㅔ ㅁㅏㅈㅅㅡㅂㄴㅣㄷㅏ ㅎㅗㅁㅍㅔㅇㅣㅈㅣㅇㅔ ㄴㅏㅇㅘㅇㅣㅆㄴㅡㄴ ㅇㅓ ㄴㅔ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/mnt/c/Users/tkd39/stt/1.Training/D03/J13/S000...</td>\n",
       "      <td>ㄴㅔ ㅇㅏㄹㄱㅔㅆㅅㅡㅂㄴㅣㄷㅏ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            wav_path  \\\n",
       "0  /mnt/c/Users/tkd39/stt/1.Training/D03/J13/S000...   \n",
       "1  /mnt/c/Users/tkd39/stt/1.Training/D03/J13/S000...   \n",
       "2  /mnt/c/Users/tkd39/stt/1.Training/D03/J13/S000...   \n",
       "3  /mnt/c/Users/tkd39/stt/1.Training/D03/J13/S000...   \n",
       "4  /mnt/c/Users/tkd39/stt/1.Training/D03/J13/S000...   \n",
       "\n",
       "                                     decomposed_text  \n",
       "0  ㄴㅔ ㄱㅏㅁㅅㅏㅎㅏㅂㄴㅣㄷㅏ ㅇㅔㄴㅆㅣㅇㅔㅅㅡ ㄱㅛㅇㅠㄱㄱㅘㅈㅓㅇ ㅁㅜㄴㅇㅢ ㅊㅔㅎ...  \n",
       "1                                        ㄴㅔ ㅇㅕㅂㅗㅅㅔㅇㅛ  \n",
       "2  ㅇㅏ ㄴㅔ ㅈㅓㄱㅣ ㄱㅡ ㅇㅔㄴㅆㅣㅇㅔㅅㅡ ㅇㅣㄴㅅㅏㄷㅏㅁㄷㅏㅇㅈㅏ ㄱㅣㅂㅗㄴ ㅅㅣ...  \n",
       "3  ㅇㅏ ㄴㅔ ㅁㅏㅈㅅㅡㅂㄴㅣㄷㅏ ㅎㅗㅁㅍㅔㅇㅣㅈㅣㅇㅔ ㄴㅏㅇㅘㅇㅣㅆㄴㅡㄴ ㅇㅓ ㄴㅔ ...  \n",
       "4                                   ㄴㅔ ㅇㅏㄹㄱㅔㅆㅅㅡㅂㄴㅣㄷㅏ  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    }
   ],
   "source": [
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.head(50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['decomposed_text'] = df['decomposed_text'].apply(remove_non_korean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2CTCTokenizer\n",
    "\n",
    "# 분해된 텍스트에서 고유한 문자 추출\n",
    "all_chars = set(''.join(train_df['decomposed_text']))\n",
    "vocab_dict = {char: idx for idx, char in enumerate(all_chars)}\n",
    "\n",
    "# 스페셜 토큰 추가\n",
    "vocab_dict[\"[PAD]\"] = len(vocab_dict)\n",
    "vocab_dict[\"[UNK]\"] = len(vocab_dict)\n",
    "vocab_dict[\"|\"] = len(vocab_dict)  # 공백 문자 대체\n",
    "\n",
    "# vocab.json 저장\n",
    "import json\n",
    "\n",
    "with open('vocab.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(vocab_dict, f, ensure_ascii=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2FeatureExtractor\n",
    "\n",
    "# feature_extractor 정의\n",
    "feature_extractor = Wav2Vec2FeatureExtractor(\n",
    "    feature_size=1,\n",
    "    sampling_rate=16000,\n",
    "    padding_value=0.0,\n",
    "    do_normalize=True,\n",
    "    return_attention_mask=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Wav2Vec2CTCTokenizer(\"vocab.json\", unk_token=\"[UNK]\", pad_token=\"[PAD]\", word_delimiter_token=\"|\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    }
   ],
   "source": [
    "import torchaudio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "\n",
    "# 로그 설정\n",
    "logging.basicConfig(filename='error.log', level=logging.ERROR)\n",
    "\n",
    "def speech_file_to_array_fn(path):\n",
    "    try:\n",
    "        speech_array, sampling_rate = torchaudio.load(path)\n",
    "        if sampling_rate != 16000:\n",
    "            resampler = torchaudio.transforms.Resample(orig_freq=sampling_rate, new_freq=16000)\n",
    "            speech_array = resampler(speech_array)\n",
    "        speech = speech_array.squeeze().numpy()\n",
    "        return speech\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing {path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def apply_with_progress(df, func):\n",
    "    speech_list = []\n",
    "    for path in tqdm(df['wav_path'], desc='Processing audio files', leave=False):\n",
    "        speech = func(path)\n",
    "        speech_list.append(speech)\n",
    "    df['speech'] = speech_list\n",
    "    return df\n",
    "\n",
    "# 데이터 적용\n",
    "train_df = apply_with_progress(train_df, speech_file_to_array_fn)\n",
    "test_df = apply_with_progress(test_df, speech_file_to_array_fn)\n",
    "\n",
    "# None 값 제거\n",
    "train_df = train_df[train_df['speech'].notnull()]\n",
    "test_df = test_df[test_df['speech'].notnull()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baa5fda52f1e472084e45f919b611823",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/45000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-26 18:56:10.213242: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-26 18:56:14.116412: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c6539da0276455384b5b01784d50ba3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict, Audio\n",
    "\n",
    "# 필요한 컬럼만 포함된 데이터프레임 생성\n",
    "train_df_small = train_df[['wav_path', 'decomposed_text']]\n",
    "test_df_small = test_df[['wav_path', 'decomposed_text']]\n",
    "\n",
    "# 데이터셋 생성\n",
    "train_dataset = Dataset.from_pandas(train_df_small, preserve_index=False)\n",
    "test_dataset = Dataset.from_pandas(test_df_small, preserve_index=False)\n",
    "\n",
    "dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'test': test_dataset\n",
    "})\n",
    "\n",
    "# 오디오 컬럼을 Audio 타입으로 캐스팅\n",
    "dataset = dataset.cast_column(\"wav_path\", Audio(sampling_rate=16000))\n",
    "\n",
    "# 전처리 함수 정의\n",
    "def prepare_dataset(batch):\n",
    "    # 오디오 데이터 로드 및 처리\n",
    "    speech_list = []\n",
    "    for audio in batch[\"wav_path\"]:\n",
    "        speech_list.append(audio[\"array\"])\n",
    "    batch[\"input_values\"] = feature_extractor(speech_list, sampling_rate=16000).input_values\n",
    "    # 레이블 인코딩\n",
    "    batch[\"labels\"] = [tokenizer(text).input_ids for text in batch[\"decomposed_text\"]]\n",
    "    return batch\n",
    "\n",
    "# 데이터셋 전처리\n",
    "dataset = dataset.map(\n",
    "    prepare_dataset,\n",
    "    remove_columns=dataset[\"train\"].column_names,\n",
    "    batched=True,\n",
    "    batch_size=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c38ca371237b4ab0be71168b8b1686c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/49 shards):   0%|          | 0/45000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80ffa0ae6ffd43479e1904097677f465",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/6 shards):   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 전처리된 데이터셋을 저장\n",
    "dataset.save_to_disk(\"/mnt/processed_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77125b226a7c489c9f2205f198a32f8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset from disk:   0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "# 저장된 데이터셋 불러오기\n",
    "dataset = load_from_disk(\"/mnt/processed_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2CTCTokenizer, Wav2Vec2FeatureExtractor\n",
    "\n",
    "# 토크나이저 로드\n",
    "tokenizer = Wav2Vec2CTCTokenizer(\n",
    "    \"vocab.json\",\n",
    "    unk_token=\"[UNK]\",\n",
    "    pad_token=\"[PAD]\",\n",
    "    word_delimiter_token=\"|\"\n",
    ")\n",
    "\n",
    "# 특징 추출기 로드\n",
    "feature_extractor = Wav2Vec2FeatureExtractor(\n",
    "    feature_size=1,\n",
    "    sampling_rate=16000,\n",
    "    padding_value=0.0,\n",
    "    do_normalize=True,\n",
    "    return_attention_mask=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-26 19:10:58.675715: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-26 19:11:01.208703: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-large-xlsr-53 and are newly initialized: ['lm_head.bias', 'lm_head.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import Wav2Vec2ForCTC\n",
    "\n",
    "# 모델 로드\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\n",
    "    \"facebook/wav2vec2-large-xlsr-53\",\n",
    "    attention_dropout=0.1,\n",
    "    hidden_dropout=0.1,\n",
    "    feat_proj_dropout=0.0,\n",
    "    mask_time_prob=0.05,\n",
    "    layerdrop=0.1,\n",
    "    ctc_loss_reduction=\"mean\",\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    "    vocab_size=len(tokenizer)\n",
    ")\n",
    "\n",
    "# 모델의 토크나이저 및 특징 추출기 설정\n",
    "model.config.gradient_checkpointing = True\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "model.config.vocab_size = len(tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Union\n",
    "import torch\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorCTCWithPadding:\n",
    "    feature_extractor: Wav2Vec2FeatureExtractor\n",
    "    tokenizer: Wav2Vec2CTCTokenizer\n",
    "    padding: Union[bool, str] = True\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[torch.Tensor, List[float]]]]) -> Dict[str, torch.Tensor]:\n",
    "        # 입력 값과 레이블을 분리\n",
    "        input_features = [{\"input_values\": feature[\"input_values\"]} for feature in features]\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "\n",
    "        # 입력 값 패딩\n",
    "        batch = self.feature_extractor.pad(\n",
    "            input_features,\n",
    "            padding=self.padding,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        # 레이블 패딩\n",
    "        labels_batch = self.tokenizer.pad(\n",
    "            label_features,\n",
    "            padding=self.padding,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        # 레이블에서 패딩된 토큰을 -100으로 설정 (CTC Loss에서 무시)\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch\n",
    "\n",
    "data_collator = DataCollatorCTCWithPadding(\n",
    "    feature_extractor=feature_extractor,\n",
    "    tokenizer=tokenizer,\n",
    "    padding=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "# 평가 지표 로드\n",
    "wer_metric = evaluate.load(\"wer\")\n",
    "cer_metric = evaluate.load(\"cer\")\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    pred_logits = pred.predictions\n",
    "    pred_ids = np.argmax(pred_logits, axis=-1)\n",
    "\n",
    "    # 예측 결과 디코딩\n",
    "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "\n",
    "    # 레이블 디코딩\n",
    "    label_ids = pred.label_ids\n",
    "    label_ids[label_ids == -100] = tokenizer.pad_token_id\n",
    "    label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
    "\n",
    "    # WER 및 CER 계산\n",
    "    wer = wer_metric.compute(predictions=pred_str, references=label_str)\n",
    "    cer = cer_metric.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "    return {\"wer\": wer, \"cer\": cer}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shin/anaconda3/envs/tensor/lib/python3.10/site-packages/transformers/training_args.py:1559: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/mnt/d/datasets/wav2vec2-finetuned-ko\",\n",
    "    group_by_length=True,\n",
    "    per_device_train_batch_size=8,  # GPU 메모리에 따라 조절하세요\n",
    "    gradient_accumulation_steps=2,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    num_train_epochs=5,\n",
    "    fp16=True,  # GPU가 FP16을 지원하지 않으면 False로 설정\n",
    "    save_steps=500,\n",
    "    eval_steps=500,\n",
    "    logging_steps=100,\n",
    "    learning_rate=1e-4,\n",
    "    warmup_steps=500,\n",
    "    save_total_limit=2,\n",
    "    report_to=\"none\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"wer\",\n",
    "    greater_is_better=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9767/131626585.py:3: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/home/shin/anaconda3/envs/tensor/lib/python3.10/site-packages/accelerate/accelerator.py:449: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14060' max='14060' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14060/14060 6:55:49, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Wer</th>\n",
       "      <th>Cer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>6.336700</td>\n",
       "      <td>3.202706</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>6.316600</td>\n",
       "      <td>3.177886</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>6.258600</td>\n",
       "      <td>3.175218</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>6.260800</td>\n",
       "      <td>3.108690</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>6.158000</td>\n",
       "      <td>3.084275</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.986130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>6.099200</td>\n",
       "      <td>3.041531</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.981696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>4.805900</td>\n",
       "      <td>1.950138</td>\n",
       "      <td>0.995460</td>\n",
       "      <td>0.541087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>2.650100</td>\n",
       "      <td>1.007917</td>\n",
       "      <td>0.790780</td>\n",
       "      <td>0.252954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>2.170800</td>\n",
       "      <td>0.794418</td>\n",
       "      <td>0.672461</td>\n",
       "      <td>0.198241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>1.932700</td>\n",
       "      <td>0.683179</td>\n",
       "      <td>0.602976</td>\n",
       "      <td>0.170880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>1.724600</td>\n",
       "      <td>0.620809</td>\n",
       "      <td>0.564291</td>\n",
       "      <td>0.156355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>1.563700</td>\n",
       "      <td>0.574596</td>\n",
       "      <td>0.522910</td>\n",
       "      <td>0.143087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>1.476200</td>\n",
       "      <td>0.534321</td>\n",
       "      <td>0.497425</td>\n",
       "      <td>0.134122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>1.481900</td>\n",
       "      <td>0.507928</td>\n",
       "      <td>0.475513</td>\n",
       "      <td>0.128178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>1.383800</td>\n",
       "      <td>0.507526</td>\n",
       "      <td>0.460253</td>\n",
       "      <td>0.123709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>1.321100</td>\n",
       "      <td>0.466607</td>\n",
       "      <td>0.444064</td>\n",
       "      <td>0.118901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>1.296800</td>\n",
       "      <td>0.457292</td>\n",
       "      <td>0.430635</td>\n",
       "      <td>0.115228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>1.219000</td>\n",
       "      <td>0.443250</td>\n",
       "      <td>0.417867</td>\n",
       "      <td>0.111370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>1.214200</td>\n",
       "      <td>0.428271</td>\n",
       "      <td>0.408737</td>\n",
       "      <td>0.108486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>1.147000</td>\n",
       "      <td>0.424275</td>\n",
       "      <td>0.404464</td>\n",
       "      <td>0.106948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>1.113100</td>\n",
       "      <td>0.411918</td>\n",
       "      <td>0.396477</td>\n",
       "      <td>0.104615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>1.102500</td>\n",
       "      <td>0.406958</td>\n",
       "      <td>0.390564</td>\n",
       "      <td>0.103021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>1.074500</td>\n",
       "      <td>0.406878</td>\n",
       "      <td>0.389102</td>\n",
       "      <td>0.102684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>1.095700</td>\n",
       "      <td>0.395323</td>\n",
       "      <td>0.379640</td>\n",
       "      <td>0.100158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>1.077900</td>\n",
       "      <td>0.395028</td>\n",
       "      <td>0.376372</td>\n",
       "      <td>0.099171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>1.067900</td>\n",
       "      <td>0.389350</td>\n",
       "      <td>0.374286</td>\n",
       "      <td>0.098549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>1.049400</td>\n",
       "      <td>0.389756</td>\n",
       "      <td>0.373091</td>\n",
       "      <td>0.098355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>1.064100</td>\n",
       "      <td>0.386221</td>\n",
       "      <td>0.371832</td>\n",
       "      <td>0.097845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=14060, training_loss=2.808842104427506, metrics={'train_runtime': 24962.5605, 'train_samples_per_second': 9.013, 'train_steps_per_second': 0.563, 'total_flos': 5.837557399850187e+19, 'train_loss': 2.808842104427506, 'epoch': 4.999111111111111})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"test\"],\n",
    "    tokenizer=feature_extractor\n",
    ")\n",
    "\n",
    "# 학습 시작\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 03:31]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results: {'eval_loss': 0.3861437141895294, 'eval_wer': 0.371920900362434, 'eval_cer': 0.09783614914198224, 'eval_runtime': 258.1407, 'eval_samples_per_second': 19.369, 'eval_steps_per_second': 2.421, 'epoch': 4.999111111111111}\n"
     ]
    }
   ],
   "source": [
    "# 모델 평가\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Evaluation Results: {eval_results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/mnt/d/datasets/wav2vec2-finetuned-ko/preprocessor_config.json']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 저장\n",
    "trainer.save_model(\"/mnt/wav2vec2-finetuned-ko\")\n",
    "tokenizer.save_pretrained(\"/mnt/wav2vec2-finetuned-ko\")\n",
    "feature_extractor.save_pretrained(\"/mnt/wav2vec2-finetuned-ko\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
